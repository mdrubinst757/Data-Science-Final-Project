---
title: "README"
author: "Max Rubinstein and Owen Phillips"
date: "Monday, May 4, 2015"
output: pdf_document
---

The following README documents the purpose and use of the files within the Data Science Final Project folder.

The files training1.csv, training2.csv, and training3.csv (found in the Data and Scraping Results folder) contain data from Moody's Analytics regarding industries in the Nashville, TN metropolitan statistical area (MSA). The files contain company information, primary NAICS code, the company's website, and a 'true' classification of whether the company is healthcare related or not (coded manually). 

Ad Hoc Scraper.py is the first webscraper we created. Using training1.csv, training2.csv, and training3.csv (the path must be changed each time), Ad Hoc.py searches for keywords we selected in the front page of each company's website. It then returns a csv containing the frequency of each keyword by website. These files are entitled scrape1.csv, scrape2.csv, and scrape3.csv. All of these files can be found in the Data and Scraping Results folder.

The file Merging Data.R then appends scrape1.csv, scrape2.csv, and scrape3.csv into one file called scrape.csv. After this point, scrape.csv can be used as the primary input for other files, as it contains all the website information as well as the true classifications.

Next, HTML Scraper.R collects the HTML code from all of the websites using scrape.csv and generates a document-term-matrix (DTM) with all the unigrams, bigrams, and trigrams from the code. This script then outputs the DTM in a dtm.csv.

CVVarSelectandTests.R inputs this DTM and using a chi-squared test, generates four lists of keywords to compare our ad hoc list against. These include the top 100 n-grams most associated with healthcare, the top 50 n-grams most associated and the bottom 50 n-grams least associated with healthcare, and the top 10 n-grams most associated with healthcare. We also run a lasso on the top 100 n-grams to get a fourth list of selected variables. These lists are all output as csvs, and can be found in the Results for Tables folder.

We then use the AdHocAnalysis.R and CVVarSelectandTests.R scripts to run different classification models on the dataframe and stores the sensitivity, specificity, and other information for each. These models we use include the Linear Probability Model, Linear Discriminant Analysis, Random Forests, Support Vector Machines (with linear and radial kernels), and K-Nearest-Neighbors. Cross-validation is used in each model to get a better estimate of the out-of-sample error rate. We output the results in results.csv and adhocresults.csv. 

Finally, Final Results.R merges these two csvs together and outputs a final table called finalresults.csv. It also generates a plot of the data, results.png. 

The final write-up of this project is Final Report.pdf. The files associated with our presentation are in the Presentation folder and include DSPresentation.R, DSPresentation.html, and several images.